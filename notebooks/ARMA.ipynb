{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install dagshub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as gourimenon8\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as gourimenon8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"gourimenon8/sp25_taxi\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"gourimenon8/sp25_taxi\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository gourimenon8/sp25_taxi initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository gourimenon8/sp25_taxi initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "# Now you can import from src\n",
    "from src.data_utils import load_and_process_taxi_data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import dagshub\n",
    "dagshub.init(repo_owner=\"gourimenon8\", repo_name=\"sp25_taxi\", mlflow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists for 2022-01.\n",
      "Loading data for 2022-01...\n",
      "Total records: 2,463,931\n",
      "Valid records: 2,415,141\n",
      "Records dropped: 48,790 (1.98%)\n",
      "Successfully processed data for 2022-01.\n",
      "File already exists for 2022-02.\n",
      "Loading data for 2022-02...\n",
      "Total records: 2,979,431\n",
      "Valid records: 2,921,118\n",
      "Records dropped: 58,313 (1.96%)\n",
      "Successfully processed data for 2022-02.\n",
      "File already exists for 2022-03.\n",
      "Loading data for 2022-03...\n",
      "Total records: 3,627,882\n",
      "Valid records: 3,551,986\n",
      "Records dropped: 75,896 (2.09%)\n",
      "Successfully processed data for 2022-03.\n",
      "File already exists for 2022-04.\n",
      "Loading data for 2022-04...\n",
      "Total records: 3,599,920\n",
      "Valid records: 3,522,113\n",
      "Records dropped: 77,807 (2.16%)\n",
      "Successfully processed data for 2022-04.\n",
      "File already exists for 2022-05.\n",
      "Loading data for 2022-05...\n",
      "Total records: 3,588,295\n",
      "Valid records: 3,509,056\n",
      "Records dropped: 79,239 (2.21%)\n",
      "Successfully processed data for 2022-05.\n",
      "File already exists for 2022-06.\n",
      "Loading data for 2022-06...\n",
      "Total records: 3,558,124\n",
      "Valid records: 3,479,411\n",
      "Records dropped: 78,713 (2.21%)\n",
      "Successfully processed data for 2022-06.\n",
      "File already exists for 2022-07.\n",
      "Loading data for 2022-07...\n",
      "Total records: 3,174,394\n",
      "Valid records: 3,096,271\n",
      "Records dropped: 78,123 (2.46%)\n",
      "Successfully processed data for 2022-07.\n",
      "File already exists for 2022-08.\n",
      "Loading data for 2022-08...\n",
      "Total records: 3,152,677\n",
      "Valid records: 3,072,196\n",
      "Records dropped: 80,481 (2.55%)\n",
      "Successfully processed data for 2022-08.\n",
      "File already exists for 2022-09.\n",
      "Loading data for 2022-09...\n",
      "Total records: 3,183,767\n",
      "Valid records: 3,106,359\n",
      "Records dropped: 77,408 (2.43%)\n",
      "Successfully processed data for 2022-09.\n",
      "File already exists for 2022-10.\n",
      "Loading data for 2022-10...\n",
      "Total records: 3,675,411\n",
      "Valid records: 3,583,466\n",
      "Records dropped: 91,945 (2.50%)\n",
      "Successfully processed data for 2022-10.\n",
      "File already exists for 2022-11.\n",
      "Loading data for 2022-11...\n",
      "Total records: 3,252,717\n",
      "Valid records: 3,165,474\n",
      "Records dropped: 87,243 (2.68%)\n",
      "Successfully processed data for 2022-11.\n",
      "File already exists for 2022-12.\n",
      "Loading data for 2022-12...\n",
      "Total records: 3,399,549\n",
      "Valid records: 3,310,530\n",
      "Records dropped: 89,019 (2.62%)\n",
      "Successfully processed data for 2022-12.\n",
      "Combining all monthly data...\n",
      "Data loading and processing complete!\n",
      "File already exists for 2023-01.\n",
      "Loading data for 2023-01...\n",
      "Total records: 3,066,766\n",
      "Valid records: 2,993,140\n",
      "Records dropped: 73,626 (2.40%)\n",
      "Successfully processed data for 2023-01.\n",
      "File already exists for 2023-02.\n",
      "Loading data for 2023-02...\n",
      "Total records: 2,913,955\n",
      "Valid records: 2,845,058\n",
      "Records dropped: 68,897 (2.36%)\n",
      "Successfully processed data for 2023-02.\n",
      "File already exists for 2023-03.\n",
      "Loading data for 2023-03...\n",
      "Total records: 3,403,766\n",
      "Valid records: 3,331,705\n",
      "Records dropped: 72,061 (2.12%)\n",
      "Successfully processed data for 2023-03.\n",
      "File already exists for 2023-04.\n",
      "Loading data for 2023-04...\n",
      "Total records: 3,288,250\n",
      "Valid records: 3,214,922\n",
      "Records dropped: 73,328 (2.23%)\n",
      "Successfully processed data for 2023-04.\n",
      "File already exists for 2023-05.\n",
      "Loading data for 2023-05...\n",
      "Total records: 3,513,649\n",
      "Valid records: 3,435,875\n",
      "Records dropped: 77,774 (2.21%)\n",
      "Successfully processed data for 2023-05.\n",
      "File already exists for 2023-06.\n",
      "Loading data for 2023-06...\n",
      "Total records: 3,307,234\n",
      "Valid records: 3,233,969\n",
      "Records dropped: 73,265 (2.22%)\n",
      "Successfully processed data for 2023-06.\n",
      "File already exists for 2023-07.\n",
      "Loading data for 2023-07...\n",
      "Total records: 2,907,108\n",
      "Valid records: 2,838,637\n",
      "Records dropped: 68,471 (2.36%)\n",
      "Successfully processed data for 2023-07.\n",
      "File already exists for 2023-08.\n",
      "Loading data for 2023-08...\n",
      "Total records: 2,824,209\n",
      "Valid records: 2,758,739\n",
      "Records dropped: 65,470 (2.32%)\n",
      "Successfully processed data for 2023-08.\n",
      "File already exists for 2023-09.\n",
      "Loading data for 2023-09...\n",
      "Total records: 2,846,722\n",
      "Valid records: 2,782,920\n",
      "Records dropped: 63,802 (2.24%)\n",
      "Successfully processed data for 2023-09.\n",
      "File already exists for 2023-10.\n",
      "Loading data for 2023-10...\n",
      "Total records: 3,522,285\n",
      "Valid records: 3,446,406\n",
      "Records dropped: 75,879 (2.15%)\n",
      "Successfully processed data for 2023-10.\n",
      "File already exists for 2023-11.\n",
      "Loading data for 2023-11...\n",
      "Total records: 3,339,715\n",
      "Valid records: 3,267,940\n",
      "Records dropped: 71,775 (2.15%)\n",
      "Successfully processed data for 2023-11.\n",
      "File already exists for 2023-12.\n",
      "Loading data for 2023-12...\n",
      "Total records: 3,376,567\n",
      "Valid records: 3,313,957\n",
      "Records dropped: 62,610 (1.85%)\n",
      "Successfully processed data for 2023-12.\n",
      "Combining all monthly data...\n",
      "Data loading and processing complete!\n"
     ]
    }
   ],
   "source": [
    "rides1 = load_and_process_taxi_data(year=2022)\n",
    "rides2=(load_and_process_taxi_data(year=2023))\n",
    "rides = pd.concat([rides1,rides2],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_rides = rides[rides[\"pickup_location_id\"] == 43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\gouri\\MLops\\sp25_taxi-main\\src\\data_utils.py:223: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  rides[\"pickup_hour\"] = rides[\"pickup_datetime\"].dt.floor(\"h\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pickup_hour  pickup_location_id  rides\n",
       "0 2022-01-01 00:00:00                  43     96\n",
       "1 2022-01-01 01:00:00                  43     60\n",
       "2 2022-01-01 02:00:00                  43     22\n",
       "3 2022-01-01 03:00:00                  43      8\n",
       "4 2022-01-01 04:00:00                  43      4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data_utils import transform_raw_data_into_ts_data\n",
    "\n",
    "ts_data = transform_raw_data_into_ts_data(temp_rides)\n",
    "ts_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_hour</th>\n",
       "      <th>pickup_location_id</th>\n",
       "      <th>rides</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-01 00:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01 01:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01 02:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01 03:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 04:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17515</th>\n",
       "      <td>2023-12-31 19:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17516</th>\n",
       "      <td>2023-12-31 20:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17517</th>\n",
       "      <td>2023-12-31 21:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17518</th>\n",
       "      <td>2023-12-31 22:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17519</th>\n",
       "      <td>2023-12-31 23:00:00</td>\n",
       "      <td>43</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17520 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              pickup_hour  pickup_location_id  rides\n",
       "0     2022-01-01 00:00:00                  43     96\n",
       "1     2022-01-01 01:00:00                  43     60\n",
       "2     2022-01-01 02:00:00                  43     22\n",
       "3     2022-01-01 03:00:00                  43      8\n",
       "4     2022-01-01 04:00:00                  43      4\n",
       "...                   ...                 ...    ...\n",
       "17515 2023-12-31 19:00:00                  43     55\n",
       "17516 2023-12-31 20:00:00                  43     72\n",
       "17517 2023-12-31 21:00:00                  43     50\n",
       "17518 2023-12-31 22:00:00                  43     28\n",
       "17519 2023-12-31 23:00:00                  43     34\n",
       "\n",
       "[17520 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_data = ts_data.drop(columns=[\"pickup_location_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          pickup_hour  rides\n",
      "0 2022-01-01 00:00:00     96\n",
      "1 2022-01-01 01:00:00     60\n",
      "2 2022-01-01 02:00:00     22\n",
      "3 2022-01-01 03:00:00      8\n",
      "4 2022-01-01 04:00:00      4\n"
     ]
    }
   ],
   "source": [
    "print(ts_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing stepwise search to minimize aic\n",
      " ARIMA(2,0,2)(0,0,0)[0]             : AIC=162977.313, Time=4.68 sec\n",
      " ARIMA(0,0,0)(0,0,0)[0]             : AIC=210122.120, Time=0.28 sec\n",
      " ARIMA(1,0,0)(0,0,0)[0]             : AIC=165205.279, Time=0.34 sec\n",
      " ARIMA(0,0,1)(0,0,0)[0]             : AIC=191455.692, Time=1.97 sec\n",
      " ARIMA(1,0,2)(0,0,0)[0]             : AIC=164599.482, Time=5.13 sec\n",
      " ARIMA(2,0,1)(0,0,0)[0]             : AIC=164969.807, Time=5.63 sec\n",
      " ARIMA(3,0,2)(0,0,0)[0]             : AIC=inf, Time=27.01 sec\n",
      " ARIMA(2,0,3)(0,0,0)[0]             : AIC=162484.750, Time=11.06 sec\n",
      " ARIMA(1,0,3)(0,0,0)[0]             : AIC=163384.864, Time=4.27 sec\n",
      " ARIMA(3,0,3)(0,0,0)[0]             : AIC=162468.514, Time=6.74 sec\n",
      " ARIMA(4,0,3)(0,0,0)[0]             : AIC=159080.981, Time=16.08 sec\n",
      " ARIMA(4,0,2)(0,0,0)[0]             : AIC=162619.471, Time=5.69 sec\n",
      " ARIMA(5,0,3)(0,0,0)[0]             : AIC=162610.899, Time=16.71 sec\n",
      " ARIMA(4,0,4)(0,0,0)[0]             : AIC=156798.051, Time=25.67 sec\n",
      " ARIMA(3,0,4)(0,0,0)[0]             : AIC=162451.439, Time=11.59 sec\n",
      " ARIMA(5,0,4)(0,0,0)[0]             : AIC=inf, Time=85.94 sec\n",
      " ARIMA(4,0,5)(0,0,0)[0]             : AIC=161958.221, Time=19.22 sec\n",
      " ARIMA(3,0,5)(0,0,0)[0]             : AIC=159052.801, Time=21.10 sec\n",
      " ARIMA(5,0,5)(0,0,0)[0]             : AIC=161677.470, Time=20.30 sec\n",
      " ARIMA(4,0,4)(0,0,0)[0] intercept   : AIC=158532.454, Time=56.15 sec\n",
      "\n",
      "Best model:  ARIMA(4,0,4)(0,0,0)[0]          \n",
      "Total fit time: 345.813 seconds\n",
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                17520\n",
      "Model:               SARIMAX(4, 0, 4)   Log Likelihood              -78390.026\n",
      "Date:                Fri, 07 Mar 2025   AIC                         156798.051\n",
      "Time:                        14:53:45   BIC                         156867.991\n",
      "Sample:                             0   HQIC                        156821.081\n",
      "                              - 17520                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "ar.L1          3.5191      0.026    136.996      0.000       3.469       3.569\n",
      "ar.L2         -4.6588      0.075    -62.382      0.000      -4.805      -4.512\n",
      "ar.L3          2.7330      0.074     36.875      0.000       2.588       2.878\n",
      "ar.L4         -0.5933      0.025    -23.619      0.000      -0.643      -0.544\n",
      "ma.L1         -2.8741      0.027   -106.117      0.000      -2.927      -2.821\n",
      "ma.L2          2.8838      0.066     43.537      0.000       2.754       3.014\n",
      "ma.L3         -1.0876      0.055    -19.946      0.000      -1.194      -0.981\n",
      "ma.L4          0.0798      0.015      5.200      0.000       0.050       0.110\n",
      "sigma2       490.8283      4.109    119.454      0.000     482.775     498.882\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   0.91   Jarque-Bera (JB):              4043.50\n",
      "Prob(Q):                              0.34   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.94   Skew:                             0.45\n",
      "Prob(H) (two-sided):                  0.02   Kurtosis:                         5.17\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    }
   ],
   "source": [
    "# !pip install pmdarima\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "# Find best ARIMA(p, d, q)\n",
    "model_auto = auto_arima(ts_data[\"rides\"], seasonal=False, stepwise=True, trace=True)\n",
    "\n",
    "# Print the best parameters\n",
    "print(model_auto.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gouri\\.conda\\envs\\mlops_project1\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               SARIMAX Results                                \n",
      "==============================================================================\n",
      "Dep. Variable:                  rides   No. Observations:                17520\n",
      "Model:                 ARIMA(4, 0, 4)   Log Likelihood              -78008.756\n",
      "Date:                Fri, 07 Mar 2025   AIC                         156037.512\n",
      "Time:                        14:59:42   BIC                         156115.223\n",
      "Sample:                             0   HQIC                        156063.100\n",
      "                              - 17520                                         \n",
      "Covariance Type:                  opg                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         73.4145      0.761     96.461      0.000      71.923      74.906\n",
      "ar.L1          1.6857      0.007    244.919      0.000       1.672       1.699\n",
      "ar.L2          0.2286      0.007     34.941      0.000       0.216       0.241\n",
      "ar.L3         -1.7011      0.006   -262.214      0.000      -1.714      -1.688\n",
      "ar.L4          0.7532      0.007    109.747      0.000       0.740       0.767\n",
      "ma.L1         -1.0918      0.010   -114.157      0.000      -1.111      -1.073\n",
      "ma.L2         -0.7781      0.009    -88.853      0.000      -0.795      -0.761\n",
      "ma.L3          1.1475      0.009    129.241      0.000       1.130       1.165\n",
      "ma.L4         -0.1654      0.009    -17.597      0.000      -0.184      -0.147\n",
      "sigma2       446.7126      3.485    128.177      0.000     439.882     453.543\n",
      "===================================================================================\n",
      "Ljung-Box (L1) (Q):                   4.31   Jarque-Bera (JB):              3671.24\n",
      "Prob(Q):                              0.04   Prob(JB):                         0.00\n",
      "Heteroskedasticity (H):               0.96   Skew:                             0.29\n",
      "Prob(H) (two-sided):                  0.12   Kurtosis:                         5.17\n",
      "===================================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Covariance matrix calculated using the outer product of gradients (complex-step).\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "# Fit the best ARIMA model (Example: ARIMA(4, 0, 4) if suggested)\n",
    "model_arima = ARIMA(ts_data[\"rides\"], order=(4, 0, 4))  # Replace with best (p, d, q)\n",
    "arima_result = model_arima.fit()\n",
    "\n",
    "# Print model summary\n",
    "print(arima_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gouri\\.conda\\envs\\mlops_project1\\lib\\site-packages\\statsmodels\\base\\model.py:607: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  warnings.warn(\"Maximum Likelihood optimization failed to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE) for ARIMA: 25.450375690190363\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Split data into train (80%) and test (20%)\n",
    "train_size = int(len(ts_data) * 0.8)\n",
    "train, test = ts_data.iloc[:train_size], ts_data.iloc[train_size:]\n",
    "\n",
    "# Fit ARIMA on training data\n",
    "model_arima = ARIMA(train[\"rides\"], order=(4, 0, 4))  # Use optimal (p,d,q)\n",
    "arima_result = model_arima.fit()\n",
    "\n",
    "# Forecast for test set\n",
    "forecast = arima_result.forecast(steps=len(test))\n",
    "\n",
    "# Compute MAE\n",
    "mae = mean_absolute_error(test[\"rides\"], forecast)\n",
    "print(\"Mean Absolute Error (MAE) for ARIMA:\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run unleashed-yak-519 at: https://dagshub.com/gourimenon8/sp25_taxi.mlflow/#/experiments/9/runs/15e20eeadcbf4d628de839c2a76a92c4\n",
      "üß™ View experiment at: https://dagshub.com/gourimenon8/sp25_taxi.mlflow/#/experiments/9\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.set_experiment(\"model_arima\")\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "        mlflow.log_metric(\"mean_absolute_error\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
