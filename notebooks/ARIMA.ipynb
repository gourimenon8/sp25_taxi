{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from pmdarima import auto_arima\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "import mlflow\n",
    "import holidays\n",
    "import dagshub\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "# Import from src\n",
    "from src.data_utils import load_and_process_taxi_data, transform_raw_data_into_ts_data\n",
    "\n",
    "# Initialize MLflow tracking\n",
    "dagshub.init(repo_owner=\"gourimenon8\", repo_name=\"sp25_taxi\", mlflow=True)\n",
    "mlflow.set_experiment(\"improved_arima_model\")\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"deep\")\n",
    "\n",
    "# Load the data\n",
    "print(\"Loading data...\")\n",
    "rides1 = load_and_process_taxi_data(year=2022)\n",
    "rides2 = load_and_process_taxi_data(year=2023)\n",
    "rides = pd.concat([rides1, rides2], ignore_index=True)\n",
    "\n",
    "# Filter for a specific pickup location\n",
    "LOCATION_ID = 43  # We can parametrize this\n",
    "print(f\"Filtering data for location ID {LOCATION_ID}...\")\n",
    "temp_rides = rides[rides[\"pickup_location_id\"] == LOCATION_ID]\n",
    "\n",
    "# Transform into time series data\n",
    "ts_data = transform_raw_data_into_ts_data(temp_rides)\n",
    "ts_data = ts_data.drop(columns=[\"pickup_location_id\"])\n",
    "\n",
    "print(f\"Time series data shape: {ts_data.shape}\")\n",
    "print(ts_data.head())\n",
    "\n",
    "# Create date/time features for better analysis\n",
    "ts_data[\"hour\"] = ts_data[\"pickup_hour\"].dt.hour\n",
    "ts_data[\"day_of_week\"] = ts_data[\"pickup_hour\"].dt.dayofweek\n",
    "ts_data[\"is_weekend\"] = ts_data[\"day_of_week\"].isin([5, 6]).astype(int)\n",
    "ts_data[\"month\"] = ts_data[\"pickup_hour\"].dt.month\n",
    "ts_data[\"day\"] = ts_data[\"pickup_hour\"].dt.day\n",
    "\n",
    "# Add US holidays\n",
    "us_holidays = holidays.US(years=[2022, 2023])\n",
    "ts_data[\"is_holiday\"] = ts_data[\"pickup_hour\"].dt.date.isin(us_holidays).astype(int)\n",
    "\n",
    "# Visualize time series data\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(ts_data[\"pickup_hour\"], ts_data[\"rides\"])\n",
    "plt.title(f\"Taxi Rides for Location ID {LOCATION_ID}\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Number of Rides\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"taxi_rides_timeseries.png\")\n",
    "plt.close()\n",
    "\n",
    "# Visualize daily and weekly patterns\n",
    "def plot_patterns(ts_data):\n",
    "    # Daily pattern\n",
    "    hourly_avg = ts_data.groupby(\"hour\")[\"rides\"].mean()\n",
    "    \n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    plt.subplot(2, 1, 1)\n",
    "    sns.barplot(x=hourly_avg.index, y=hourly_avg.values)\n",
    "    plt.title(\"Average Rides by Hour of Day\")\n",
    "    plt.xlabel(\"Hour of Day\")\n",
    "    plt.ylabel(\"Average Rides\")\n",
    "    \n",
    "    # Weekly pattern\n",
    "    daily_avg = ts_data.groupby(\"day_of_week\")[\"rides\"].mean()\n",
    "    day_names = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "    \n",
    "    plt.subplot(2, 1, 2)\n",
    "    sns.barplot(x=[day_names[i] for i in daily_avg.index], y=daily_avg.values)\n",
    "    plt.title(\"Average Rides by Day of Week\")\n",
    "    plt.xlabel(\"Day of Week\")\n",
    "    plt.ylabel(\"Average Rides\")\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"taxi_rides_patterns.png\")\n",
    "    plt.close()\n",
    "\n",
    "plot_patterns(ts_data)\n",
    "\n",
    "# Check stationarity\n",
    "def check_stationarity(timeseries):\n",
    "    # Calculate rolling statistics\n",
    "    rolmean = timeseries.rolling(window=24).mean()\n",
    "    rolstd = timeseries.rolling(window=24).std()\n",
    "    \n",
    "    # Plot rolling statistics\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.plot(timeseries, label='Original')\n",
    "    plt.plot(rolmean, label='Rolling Mean')\n",
    "    plt.plot(rolstd, label='Rolling Std')\n",
    "    plt.legend()\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"stationarity_check.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Perform Dickey-Fuller test\n",
    "    print('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(timeseries.dropna(), autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key, value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print(dfoutput)\n",
    "    \n",
    "    return dftest[1] <= 0.05  # Return True if stationary\n",
    "\n",
    "is_stationary = check_stationarity(ts_data[\"rides\"])\n",
    "print(f\"Is the time series stationary? {is_stationary}\")\n",
    "\n",
    "# If not stationary, differentiate the series\n",
    "diff_order = 0\n",
    "diff_series = ts_data[\"rides\"].copy()\n",
    "if not is_stationary:\n",
    "    diff_series = ts_data[\"rides\"].diff().dropna()\n",
    "    diff_order = 1\n",
    "    is_diff_stationary = check_stationarity(diff_series)\n",
    "    print(f\"Is the differenced series stationary? {is_diff_stationary}\")\n",
    "\n",
    "# Plot ACF and PACF to help identify (p,d,q) orders manually\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.subplot(211)\n",
    "plot_acf(diff_series.dropna(), ax=plt.gca(), lags=48)\n",
    "plt.subplot(212)\n",
    "plot_pacf(diff_series.dropna(), ax=plt.gca(), lags=48)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"acf_pacf_plots.png\")\n",
    "plt.close()\n",
    "\n",
    "# Split data for training and testing\n",
    "train_size = int(len(ts_data) * 0.8)\n",
    "train = ts_data.iloc[:train_size]\n",
    "test = ts_data.iloc[train_size:]\n",
    "print(f\"Training set size: {train.shape}, Test set size: {test.shape}\")\n",
    "\n",
    "# Define a function to evaluate models\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    \n",
    "    print(f\"{model_name} Performance Metrics:\")\n",
    "    print(f\"MAE: {mae:.2f}\")\n",
    "    print(f\"RMSE: {rmse:.2f}\")\n",
    "    print(f\"MAPE: {mape:.2f}%\")\n",
    "    \n",
    "    # Plot actual vs predicted\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    plt.plot(y_true.index, y_true, label='Actual')\n",
    "    plt.plot(y_true.index, y_pred, label='Predicted', alpha=0.7)\n",
    "    plt.title(f'{model_name}: Actual vs Predicted')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Number of Rides')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{model_name.lower().replace(' ', '_')}_prediction.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    return {\"mae\": mae, \"rmse\": rmse, \"mape\": mape}\n",
    "\n",
    "\n",
    "\n",
    "# 1. Auto ARIMA without seasonality\n",
    "print(\"\\nFitting Auto ARIMA without seasonality...\")\n",
    "model_auto = auto_arima(\n",
    "    train[\"rides\"], \n",
    "    seasonal=False,\n",
    "    stepwise=True,\n",
    "    trace=True,\n",
    "    error_action=\"ignore\",\n",
    "    suppress_warnings=True,\n",
    "    max_order=None,\n",
    "    d=diff_order\n",
    ")\n",
    "print(model_auto.summary())\n",
    "\n",
    "# Get the best parameters\n",
    "best_p, best_d, best_q = model_auto.order\n",
    "\n",
    "# Forecast with Auto ARIMA\n",
    "forecast_auto = model_auto.predict(n_periods=len(test))\n",
    "auto_metrics = evaluate_model(test[\"rides\"], forecast_auto, \"Auto ARIMA (Non-Seasonal)\")\n",
    "\n",
    "# 2. SARIMA Model (Seasonal ARIMA)\n",
    "print(\"\\nFitting SARIMA with seasonality...\")\n",
    "# Use daily seasonality (24 hours)\n",
    "seasonal_period = 24\n",
    "\n",
    "model_sarima = auto_arima(\n",
    "    train[\"rides\"],\n",
    "    seasonal=True,\n",
    "    m=seasonal_period,\n",
    "    stepwise=True,\n",
    "    trace=True,\n",
    "    error_action=\"ignore\",\n",
    "    suppress_warnings=True,\n",
    "    d=diff_order,\n",
    "    max_order=10\n",
    ")\n",
    "print(model_sarima.summary())\n",
    "\n",
    "# Get the best parameters for SARIMA\n",
    "best_p, best_d, best_q = model_sarima.order\n",
    "best_P, best_D, best_Q, best_m = model_sarima.seasonal_order\n",
    "\n",
    "# Forecast with SARIMA\n",
    "forecast_sarima = model_sarima.predict(n_periods=len(test))\n",
    "sarima_metrics = evaluate_model(test[\"rides\"], forecast_sarima, \"SARIMA (Seasonal)\")\n",
    "\n",
    "# 3. Manual ARIMA with external regressors (features)\n",
    "\n",
    "# Prepare external regressors (features)\n",
    "exog_train = train[[\"hour\", \"day_of_week\", \"is_weekend\", \"is_holiday\"]].values\n",
    "exog_test = test[[\"hour\", \"day_of_week\", \"is_weekend\", \"is_holiday\"]].values\n",
    "\n",
    "print(\"\\nFitting ARIMAX with external regressors...\")\n",
    "model_arimax = SARIMAX(\n",
    "    train[\"rides\"],\n",
    "    exog=exog_train,\n",
    "    order=(best_p, best_d, best_q),\n",
    "    seasonal_order=(0, 0, 0, 0),  # No seasonality as we're using external regressors\n",
    "    enforce_stationarity=False\n",
    ")\n",
    "arimax_result = model_arimax.fit(disp=False)\n",
    "print(arimax_result.summary())\n",
    "\n",
    "# Forecast with ARIMAX\n",
    "forecast_arimax = arimax_result.forecast(steps=len(test), exog=exog_test)\n",
    "arimax_metrics = evaluate_model(test[\"rides\"], forecast_arimax, \"ARIMAX with Regressors\")\n",
    "\n",
    "# Compare all models\n",
    "models = [\"Auto ARIMA\", \"SARIMA\", \"ARIMAX\"]\n",
    "maes = [auto_metrics[\"mae\"], sarima_metrics[\"mae\"], arimax_metrics[\"mae\"]]\n",
    "rmses = [auto_metrics[\"rmse\"], sarima_metrics[\"rmse\"], arimax_metrics[\"rmse\"]]\n",
    "mapes = [auto_metrics[\"mape\"], sarima_metrics[\"mape\"], arimax_metrics[\"mape\"]]\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.bar(models, maes)\n",
    "plt.title(\"Mean Absolute Error (MAE)\")\n",
    "plt.ylabel(\"MAE\")\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.bar(models, rmses)\n",
    "plt.title(\"Root Mean Squared Error (RMSE)\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.bar(models, mapes)\n",
    "plt.title(\"Mean Absolute Percentage Error (MAPE)\")\n",
    "plt.ylabel(\"MAPE (%)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"model_comparison.png\")\n",
    "plt.close()\n",
    "\n",
    "# Determine the best model\n",
    "best_model_index = np.argmin(maes)\n",
    "best_model_name = models[best_model_index]\n",
    "print(f\"\\nBest model based on MAE: {best_model_name}\")\n",
    "\n",
    "# Log results to MLflow\n",
    "with mlflow.start_run():\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"best_model\", best_model_name)\n",
    "    \n",
    "    if best_model_name == \"Auto ARIMA\":\n",
    "        mlflow.log_param(\"order\", model_auto.order)\n",
    "    elif best_model_name == \"SARIMA\":\n",
    "        mlflow.log_param(\"order\", model_sarima.order)\n",
    "        mlflow.log_param(\"seasonal_order\", model_sarima.seasonal_order)\n",
    "    else:  # ARIMAX\n",
    "        mlflow.log_param(\"order\", arimax_result.model.order)\n",
    "        mlflow.log_param(\"used_regressors\", [\"hour\", \"day_of_week\", \"is_weekend\", \"is_holiday\"])\n",
    "    \n",
    "    # Log metrics\n",
    "    mlflow.log_metric(\"mae\", maes[best_model_index])\n",
    "    mlflow.log_metric(\"rmse\", rmses[best_model_index])\n",
    "    mlflow.log_metric(\"mape\", mapes[best_model_index])\n",
    "    \n",
    "    # Log artifacts\n",
    "    mlflow.log_artifact(\"taxi_rides_timeseries.png\")\n",
    "    mlflow.log_artifact(\"taxi_rides_patterns.png\")\n",
    "    mlflow.log_artifact(\"stationarity_check.png\")\n",
    "    mlflow.log_artifact(\"acf_pacf_plots.png\")\n",
    "    mlflow.log_artifact(\"model_comparison.png\")\n",
    "    \n",
    "    if best_model_name == \"Auto ARIMA\":\n",
    "        mlflow.log_artifact(\"auto_arima_prediction.png\")\n",
    "    elif best_model_name == \"SARIMA\":\n",
    "        mlflow.log_artifact(\"sarima_prediction.png\")\n",
    "    else:  # ARIMAX\n",
    "        mlflow.log_artifact(\"arimax_with_regressors_prediction.png\")\n",
    "\n",
    "print(\"Model training and evaluation complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "collage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
