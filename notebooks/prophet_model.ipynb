{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as gourimenon8\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as gourimenon8\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"gourimenon8/sp25_taxi\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"gourimenon8/sp25_taxi\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository gourimenon8/sp25_taxi initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository gourimenon8/sp25_taxi initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists for 2022-01.\n",
      "Loading data for 2022-01...\n",
      "Total records: 2,463,931\n",
      "Valid records: 2,415,141\n",
      "Records dropped: 48,790 (1.98%)\n",
      "Successfully processed data for 2022-01.\n",
      "File already exists for 2022-02.\n",
      "Loading data for 2022-02...\n",
      "Total records: 2,979,431\n",
      "Valid records: 2,921,118\n",
      "Records dropped: 58,313 (1.96%)\n",
      "Successfully processed data for 2022-02.\n",
      "File already exists for 2022-03.\n",
      "Loading data for 2022-03...\n",
      "Total records: 3,627,882\n",
      "Valid records: 3,551,986\n",
      "Records dropped: 75,896 (2.09%)\n",
      "Successfully processed data for 2022-03.\n",
      "File already exists for 2022-04.\n",
      "Loading data for 2022-04...\n",
      "Total records: 3,599,920\n",
      "Valid records: 3,522,113\n",
      "Records dropped: 77,807 (2.16%)\n",
      "Successfully processed data for 2022-04.\n",
      "File already exists for 2022-05.\n",
      "Loading data for 2022-05...\n",
      "Total records: 3,588,295\n",
      "Valid records: 3,509,056\n",
      "Records dropped: 79,239 (2.21%)\n",
      "Successfully processed data for 2022-05.\n",
      "File already exists for 2022-06.\n",
      "Loading data for 2022-06...\n",
      "Total records: 3,558,124\n",
      "Valid records: 3,479,411\n",
      "Records dropped: 78,713 (2.21%)\n",
      "Successfully processed data for 2022-06.\n",
      "File already exists for 2022-07.\n",
      "Loading data for 2022-07...\n",
      "Total records: 3,174,394\n",
      "Valid records: 3,096,271\n",
      "Records dropped: 78,123 (2.46%)\n",
      "Successfully processed data for 2022-07.\n",
      "File already exists for 2022-08.\n",
      "Loading data for 2022-08...\n",
      "Total records: 3,152,677\n",
      "Valid records: 3,072,196\n",
      "Records dropped: 80,481 (2.55%)\n",
      "Successfully processed data for 2022-08.\n",
      "File already exists for 2022-09.\n",
      "Loading data for 2022-09...\n",
      "Total records: 3,183,767\n",
      "Valid records: 3,106,359\n",
      "Records dropped: 77,408 (2.43%)\n",
      "Successfully processed data for 2022-09.\n",
      "File already exists for 2022-10.\n",
      "Loading data for 2022-10...\n",
      "Total records: 3,675,411\n",
      "Valid records: 3,583,466\n",
      "Records dropped: 91,945 (2.50%)\n",
      "Successfully processed data for 2022-10.\n",
      "File already exists for 2022-11.\n",
      "Loading data for 2022-11...\n",
      "Total records: 3,252,717\n",
      "Valid records: 3,165,474\n",
      "Records dropped: 87,243 (2.68%)\n",
      "Successfully processed data for 2022-11.\n",
      "File already exists for 2022-12.\n",
      "Loading data for 2022-12...\n",
      "Total records: 3,399,549\n",
      "Valid records: 3,310,530\n",
      "Records dropped: 89,019 (2.62%)\n",
      "Successfully processed data for 2022-12.\n",
      "Combining all monthly data...\n",
      "Data loading and processing complete!\n",
      "File already exists for 2023-01.\n",
      "Loading data for 2023-01...\n",
      "Total records: 3,066,766\n",
      "Valid records: 2,993,140\n",
      "Records dropped: 73,626 (2.40%)\n",
      "Successfully processed data for 2023-01.\n",
      "File already exists for 2023-02.\n",
      "Loading data for 2023-02...\n",
      "Total records: 2,913,955\n",
      "Valid records: 2,845,058\n",
      "Records dropped: 68,897 (2.36%)\n",
      "Successfully processed data for 2023-02.\n",
      "File already exists for 2023-03.\n",
      "Loading data for 2023-03...\n",
      "Total records: 3,403,766\n",
      "Valid records: 3,331,705\n",
      "Records dropped: 72,061 (2.12%)\n",
      "Successfully processed data for 2023-03.\n",
      "File already exists for 2023-04.\n",
      "Loading data for 2023-04...\n",
      "Total records: 3,288,250\n",
      "Valid records: 3,214,922\n",
      "Records dropped: 73,328 (2.23%)\n",
      "Successfully processed data for 2023-04.\n",
      "File already exists for 2023-05.\n",
      "Loading data for 2023-05...\n",
      "Total records: 3,513,649\n",
      "Valid records: 3,435,875\n",
      "Records dropped: 77,774 (2.21%)\n",
      "Successfully processed data for 2023-05.\n",
      "File already exists for 2023-06.\n",
      "Loading data for 2023-06...\n",
      "Total records: 3,307,234\n",
      "Valid records: 3,233,969\n",
      "Records dropped: 73,265 (2.22%)\n",
      "Successfully processed data for 2023-06.\n",
      "File already exists for 2023-07.\n",
      "Loading data for 2023-07...\n",
      "Total records: 2,907,108\n",
      "Valid records: 2,838,637\n",
      "Records dropped: 68,471 (2.36%)\n",
      "Successfully processed data for 2023-07.\n",
      "File already exists for 2023-08.\n",
      "Loading data for 2023-08...\n",
      "Total records: 2,824,209\n",
      "Valid records: 2,758,739\n",
      "Records dropped: 65,470 (2.32%)\n",
      "Error processing data for 2023-08: Unable to allocate 253. MiB for an array with shape (12, 2758739) and data type float64\n",
      "File already exists for 2023-09.\n",
      "Loading data for 2023-09...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from prophet import Prophet\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "\n",
    "# Now you can import from src\n",
    "from src.data_utils import load_and_process_taxi_data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import dagshub\n",
    "dagshub.init(repo_owner=\"gourimenon8\", repo_name=\"sp25_taxi\", mlflow=True)\n",
    "\n",
    "\n",
    "# Create your own data transformation function\n",
    "def create_time_series_data(df):\n",
    "    \"\"\"\n",
    "    Transform raw taxi data into time series format\n",
    "    \"\"\"\n",
    "    # Implement your own transformation logic\n",
    "    if df.empty:\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # Extract hour from pickup datetime\n",
    "    df['pickup_hour'] = df['pickup_datetime'].dt.floor('H')\n",
    "    \n",
    "    # Count rides by location and hour\n",
    "    ts_data = df.groupby(['pickup_location_id', 'pickup_hour']).size().reset_index(name='rides')\n",
    "    \n",
    "    return ts_data\n",
    "\n",
    "# Main analysis\n",
    "try:\n",
    "    rides1 = load_and_process_taxi_data(year=2022)\n",
    "    rides2=(load_and_process_taxi_data(year=2023))\n",
    "    rides = pd.concat([rides1,rides2],ignore_index=True)\n",
    "    # If data loading worked, process it\n",
    "    if not (rides1.empty or rides2.empty):\n",
    "        rides = pd.concat([rides1, rides2], ignore_index=True)\n",
    "        ts_data = create_time_series_data(rides)\n",
    "    else:\n",
    "        # Create sample data for demonstration\n",
    "        print(\"Using sample data for demonstration\")\n",
    "        # Generate synthetic time series data\n",
    "        hours = pd.date_range(start='2022-01-01', end='2023-12-31', freq='H')\n",
    "        locations = [43, 151, 239]  # Example location IDs\n",
    "        \n",
    "        data = []\n",
    "        for loc in locations:\n",
    "            # Create time pattern with daily and weekly seasonality\n",
    "            for h in hours:\n",
    "                # Hourly pattern (more rides during day, fewer at night)\n",
    "                hour_factor = np.sin(h.hour / 24 * 2 * np.pi) + 1.5\n",
    "                # Weekly pattern (weekdays vs weekends)\n",
    "                day_factor = 0.7 if h.dayofweek >= 5 else 1.0\n",
    "                # Base count with some randomness\n",
    "                count = int(max(0, 10 * hour_factor * day_factor + np.random.normal(0, 3)))\n",
    "                data.append([loc, h, count])\n",
    "        \n",
    "        ts_data = pd.DataFrame(data, columns=['pickup_location_id', 'pickup_hour', 'rides'])\n",
    "    \n",
    "    # Select a location for analysis\n",
    "    location_id = 43  # Choose a location ID relevant to your analysis\n",
    "    prop_df = ts_data[ts_data[\"pickup_location_id\"] == location_id].copy()\n",
    "    \n",
    "    # Drop unnecessary columns and rename for Prophet\n",
    "    prop_df = prop_df.drop(columns=[\"pickup_location_id\"])\n",
    "    prop_df = prop_df.rename(columns={'pickup_hour': 'ds', 'rides': 'y'})\n",
    "    \n",
    "    # Ensure correct data types\n",
    "    prop_df['ds'] = pd.to_datetime(prop_df['ds'])\n",
    "    prop_df['y'] = pd.to_numeric(prop_df['y'])\n",
    "    \n",
    "    # Train Prophet model\n",
    "    model = Prophet()\n",
    "    model.fit(prop_df)\n",
    "    \n",
    "    # Create forecast\n",
    "    future = model.make_future_dataframe(periods=12, freq='H')\n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"Last 12 predictions:\")\n",
    "    print(forecast[['ds', 'yhat', 'yhat_lower', 'yhat_upper']].tail(12))\n",
    "    \n",
    "    # Plot results\n",
    "    fig = model.plot(forecast)\n",
    "    plt.title(f\"Ride Forecast for Location {location_id}\")\n",
    "    plt.savefig(\"forecast_plot.png\")\n",
    "    \n",
    "    # Plot components\n",
    "    fig_comp = model.plot_components(forecast)\n",
    "    plt.savefig(\"forecast_components.png\")\n",
    "    \n",
    "    # Evaluate model\n",
    "    results = prop_df.merge(forecast[['ds', 'yhat']], on='ds', how='inner')\n",
    "    mae = mean_absolute_error(results.dropna()['y'], results.dropna()['yhat'])\n",
    "    print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "    \n",
    "    # Try hyperparameter tuning\n",
    "    print(\"\\nTuning model hyperparameters...\")\n",
    "    models = []\n",
    "    maes = []\n",
    "    \n",
    "    # Test different changepoint_prior_scale values\n",
    "    for changepoint_prior_scale in [0.001, 0.01, 0.1, 0.5]:\n",
    "        m = Prophet(changepoint_prior_scale=changepoint_prior_scale)\n",
    "        m.fit(prop_df)\n",
    "        future = m.make_future_dataframe(periods=12, freq='H')\n",
    "        fcst = m.predict(future)\n",
    "        \n",
    "        # Calculate MAE\n",
    "        results = prop_df.merge(fcst[['ds', 'yhat']], on='ds', how='inner')\n",
    "        current_mae = mean_absolute_error(results.dropna()['y'], results.dropna()['yhat'])\n",
    "        \n",
    "        models.append(m)\n",
    "        maes.append(current_mae)\n",
    "        print(f\"  changepoint_prior_scale={changepoint_prior_scale}, MAE: {current_mae:.2f}\")\n",
    "    \n",
    "    # Find best model\n",
    "    best_idx = np.argmin(maes)\n",
    "    best_model = models[best_idx]\n",
    "    best_params = f\"changepoint_prior_scale={[0.001, 0.01, 0.1, 0.5][best_idx]}\"\n",
    "    print(f\"\\nBest model: {best_params}, MAE: {maes[best_idx]:.2f}\")\n",
    "    \n",
    "    # Generate final forecast with best model\n",
    "    future = best_model.make_future_dataframe(periods=12, freq='H')\n",
    "    final_forecast = best_model.predict(future)\n",
    "    \n",
    "    # Plot final forecast\n",
    "    fig = best_model.plot(final_forecast)\n",
    "    plt.title(f\"Best Model Forecast (Location {location_id}, {best_params})\")\n",
    "    plt.savefig(\"best_forecast_plot.png\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"Make sure you have the required data files and libraries installed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
